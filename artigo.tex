\documentclass[]{IEEEphot}
\usepackage{minted}

\jvol{01}
\jnum{01}
\jmonth{Novembro}
\pubyear{2021}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\begin{document}

\title{Trabalho 1 de Aprendizado de Máquina 1}

\author{Bárbara Dib Oliveira (769717) \\
  Igor Teixeira Machado (769708) \\
  Lucas Machado Cid (769841) \\
  Vinicius Quaresma da Luz (769836)}

\affil{Universidade Federal de São Carlos \\ Departamento de Computação}  

\maketitle

\markboth{Departamento de Computação}{Trabalho 1 de AM1}



\section{Introdução}

A educação é um pilar indispensável para o desenvolvimento de qualquer nação. Permite que as pessoas engajem em atividades mais complexas e bem remuneradas, e por conseguinte, com maior potencial de impacto social. Ante este fato, compreender os fatores e nuances que interferem na qualidade do aprendizado em todos os níveis de ensino são tarefas de elevado interesse para a sociedade como um todo.

\section{Apresentação do problema}

Tomar ações para mitigar e evitar a má performance acadêmica é de imprescindível importância para que seja garantida a qualidade e a retenção do ensino. O desafio, portanto, é fazer isso em posse de métricas relativamente simples, mas ainda significativas, que possam ser coletadas pelas mais diversas instituições e usadas para agir sobre o problema

O objetivo deste artigo é explorar um modelo classificatório eficiente que, munido de métricas adequadas, possa inferir com precisão satisfatória se a performance daquele aluno será suficiente ou não para que seja aprovado. Concomitantemente, busca-se explorar a relação de métricas extraescolares com os resultados alcançados pelo aluno, explorando a responsabilidade das instituições de apoiar seus membros em aspectos que vão além do cotidiano acadêmico.

Para isso, utilizou-se dados coletados a partir de duas instituições de ensino de Portugal, cujos atributos coletados são melhor descritos na seção \textit{ad hoc} deste documento.

\section{Descrição dos dados}

Há dois conjuntos de dados diferentes que podem ser utilizados no presente trabalho: um deles está relacionado às notas de alunos na matéria de Matemática (com 395 exemplos) e o outro refere-se às suas notas de Língua Portuguesa (com 649 exemplos). Como o segundo dataset possui mais exemplos, foi o escolhido para ser analisado. É importante ressaltar que os atributos contidos nos dois conjuntos são os mesmos e que os dados possuem duas origens diferentes: relatórios internos das escolas frequentadas e questionários respondidos pelos alunos.

Da primeira fonte, foram extraídos dados de falta às aulas, média do primeiro semestre do ano letivo, do segundo semestre e a nota final (cada uma dessas médias, seguindo o padrão europeu, tem 0 como nota mínima e 20 como máxima). Já a segunda fonte de dados, as respostas dos alunos ao questionário, é composta por informações sociais, demográficas e emocionais. Algumas delas foram classificadas como \textbf{binárias}: sexo (F ou M), escola na qual o aluno está matriculado (no caso, Gabriel Moureira e ou Mousinho da Silveira), tipo de endereço (se o aluno reside em área urbana ou rural), status de habitação dos pais (se moram juntos ou separados), tamanho da família (até três integrantes ou mais de três), reforço escolar (atende ou não), apoio educacional familiar (sim ou não), atividades extracurriculares (sim ou não), aulas particulares (sim ou não), acesso à internet em casa (sim ou não), jardim de infância (frequentou ou não), ensino superior (tem ou não interesse em cursar) e relacionamento (está em um relacionamento romântico ou não). Há também dados \textbf{numéricos}: idade do aluno em anos (valores entre 15 e 22), nível de escolaridade da mãe e do pai (sendo 0 - nenhum, 1 - fundamental I, 2 - fundamental II, 3 - ensino médio e 4 - ensino superior), qualidade das relações familiares (é um inteiro de 1 a 5, sendo 1 - muito ruim e 5 - excelente), tempo do trajeto de casa à escola (1 - menos de 15 minutos, 2 - entre 15 e 30 minutos, 3 - entre 30 minutos e uma hora e 4 - mais de uma hora), número de reprovações anteriores na matéria (n no intervalo 1 ≤ n < 3, do contrário 4), tempo de lazer após o horário de aula (é um inteiro de 1 a 5, sendo 1 - pouquíssimo tempo e 5 - muitíssimo tempo), sair com os amigos (é um inteiro de 1 a 5, sendo 1 - muito raramente e 5 - muito frequentemente), consumo de álcool aos fins de semana e durante a semana (é um inteiro de 1 a 5, sendo 1 - muito baixo e 5 - muito alto) e estado de saúde atual (é um inteiro de 1 a 5, sendo 1 - muito ruim e 5 - excelente). Finalmente, há também dados classificados como \textbf{nominais}. São eles: ocupação da mãe e do pai (professor, profissional da saúde, serviços civis, trabalho doméstico ou outro), guardião do aluno (mãe, pai ou outro), motivo de escolha da escola (próxima de casa, reputação, preferência de curso ou outro).

\section{Descrição dos métodos utilizados}
\subsection{Modelos de classificação}
\subsubsection{Decision Tree}

As Decision Trees (ou Árvores de Decisão) são um dos modelos de classificação mais populares por conta de sua alta interpretabilidade e simplicidade. Nele, cada nó representa uma decisão a ser tomada, a qual está intimamente relacionada aos possíveis valores dos dados em questão; para prosseguir para o próximo nível é necessário tomar uma “decisão”, neste caso, verificar se o dado sendo classificado satisfaz ou não a condição apresentada no nó (em caso afirmativo, deve-se prosseguir para um lado, se não, para outro). Esse processo é repetido até chegarmos a um nó folha, onde o dado é efetivamente classificado.

Para a criação da árvore de decisão, em cada nó é escolhida uma condição que melhor divide o conjunto de dados segundo algum critério (como por exemplo a entropia, independência de distribuições ou disparidade dos conjuntos). A partir daí, a árvore se ramifica. Esse processo é realizado para cada novo ramo gerado até que o conjunto de dados esteja suficientemente separado ou não haja mais atributos para dividi-los.

Apesar de ser um modelo de classificação mais simples, as Árvores de Decisão ainda sim são eficientes, fazendo com que este modelo recorrentemente apareça como uma opção antes de partir para algoritmos mais complexos. Dentre suas principais vantagens está a robustez frente a \textit{outliers} e o fato de serem não-paramétricas.

Ainda assim, possuem desvantagens. Por conta de sua natureza e da forma como é feita a seleção de atributos, este modelo é muito sensível a valores ausentes; isto é, dados que não apresentem algum dos atributos (nesses casos é necessário que seja feito um pré-processamento dos dados para que o modelo possa ser utilizado). Outra desvantagem é sua instabilidade, uma vez que as decisões nos nós da árvore são escolhidos baseados nos exemplos dos dados de treino: tirar apenas um destes dados pode gerar uma árvore completamente diferente.

No nosso caso, o conjunto de dados não apresentou atributos ausentes, sendo possível utilizar o modelo sem maiores processamentos. 

\begin{listing}[!ht]
\begin{minted}{python}
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

classifier = DecisionTreeClassifier()
classifier.fit(x_tr, y_tr)
y_pred = classifier.predict(x_te)

accuracy_score(y_te, y_pred)
\end{minted}

\caption{Código usado para implementar a Decision Tree}

\end{listing}

\subsubsection{k-Nearest Neighbors}

O K-Nearest Neighbors (ou k-NN), é um modelo baseado no princípio de que coisas semelhantes geralmente estão próximas umas das outras. Neste modelo, recebemos como entrada do algoritmo o hiperparâmetro k, que será usado para determinar a classe de uma nova entrada através da comparação com os k vizinhos mais próximos. 

Poderíamos, inicialmente, analisar estes k vizinhos mais próximos e atribuir para o novo dado a classe que mais se sobressai; nesse caso, cada exemplo contribuiria igualmente com um “voto” para a decisão. Entretanto, essa proximidade pode ser medida seguindo uma série de critérios. Podemos, por exemplo, utilizar medidas de distância variadas (como a distância euclidiana, a distância de Manhattan ou alguma outra) e atribuir peso para os “votos” de acordo com esta distância; é possível também atribuir pesos diferentes aos atributos, variar o valor de k, entre outras coisas.

Por se basear na distância do novo dado para os vizinhos mais próximos, este modelo não precisa de treino, fazendo com que ele tenha baixo custo no treinamento. Entretanto, ele é custoso na hora da classificação, uma vez que precisa calcular a distância para os k vizinhos mais próximos para cada novo dado a ser classificado.

No nosso caso, para este algoritmo foi necessário padronizar os atributos numéricos, uma vez que atributos com maior amplitude acabavam tendo maior importância no cálculo da distância.


\begin{listing}[!ht]
\begin{minted}{python}
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

classifier = DecisionTreeClassifier()
classifier.fit(x_tr, y_tr)
y_pred = classifier.predict(x_te)

accuracy_score(y_te, y_pred)
\end{minted}

\caption{Código usado para implementar o kNN}

\end{listing}

\subsubsection{Naive Bayes}

O Naive Bayes é um modelo baseado no teorema de Bayes que se sustenta na suposição de que o valor de todos os atributos são independentes uns dos outros; isto é, a ocorrência de um valor qualquer para algum atributo não interferirá em nada na probabilidade de ocorrência dos valores nos outros atributos. Para determinar a classificação de um novo dado, inicialmente calculamos a probabilidade de que o dado pertença a cada uma das classes, seguindo a seguinte proporcionalidade:

\begin{equation}
    P(y_i|x) \propto P(y_i) \prod_{j=1}^m P(x_j | y_i)
\end{equation}

Aqui temos que a probabilidade de $x$ pertencer à i-ésima classe ($P(y_i|x)$) é proporcional (\propto) a probabilidade de ocorrência da classe $y_i (P(y_i))$ multiplicada pelo produtório da probabilidade de ocorrência do valor $x_j$ para o atributo $j$ de $x$ dada a ocorrência da classe $y_i$ com $j$ variando de 1 até $m$ (sendo $m$ o número de atributos). Por fim, atribuímos ao exemplo a classe que tiver maior probabilidade.

Dentre suas vantagens temos sua robustez frente à presença de ruídos e atributos irrelevantes, uma vez que estes pouco afetam os resultados, bem como sua eficiência e interpretabilidade. Já como desvantagens temos algo natural do próprio modelo: sua \textit{ingenuidade} ao desconsiderar possíveis interdependências entre os atributos.

\begin{listing}[!ht]
\begin{minted}{python}
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

classifier = GaussianNB()

classifier.fit(x_tr.toarray(), y_tr)

y_pred = classifier.predict(x_te.toarray())
accuracy_score(y_te, y_pred)
\end{minted}

\caption{Código usado para implementar o Naive Bayes}

\end{listing}

\subsubsection{Random Forest}

Algoritmo que opera de maneira análoga à Árvore de Decisão, fazendo partições aleatórias para os conjuntos de teste e treinamento. Com isto, gera diversas árvores de decisão, \textit{modus operandi} que lhe rende o nome que possui.

\newpage

\begin{listing}[!ht]
\begin{minted}{python}
# Importa o random forest
from sklearn.ensemble import RandomForestClassifier

# Calcula o random forest
classifier = RandomForestClassifier()

# Usa o classifier para treinar
classifier.fit(x_tr, y_tr)

# Imprime a acurácia
y_pred = classifier.predict(x_te)

rf_acc = accuracy_score(y_te, y_pred)

# imprime os resultados
print('Acurácia obtida: ', rf_acc)
add_to_rank({'classifier': 'Random Forest', 'score': rf_acc})
\end{minted}

\caption{Código usado para implementar o Random Forest}
\end{listing}

\subsection{Técnicas}

\subsubsection{Grid Search}

Para grande parte dos modelos utilizados, uma série de hiperparâmetros com os mais variados valores podiam ser passados para os classificadores. Por este motivo, se fez necessária a utilização de uma técnica que permitisse a permutação entre tais hiperparâmetros de modo que fosse possível encontrar a configuração ótima para cada modelo. Para isso utilizamos a \textit{Grid Search}, uma ferramenta para a qual são passados um param grid (um objeto contendo os possíveis valores para cada hiperparâmetro) e um classificador; a ferramenta fica portanto responsável por encontrar a configuração ótima para o classificador baseada na param grid passada.

Abaixo temos um exemplo da ferramenta sendo utilizada para uma Decision Tree:

\begin{listing}[!ht]
\begin{minted}{python}
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

classifier = DecisionTreeClassifier()
param_grid = {'criterion': ['entropy', 'gini'],
             'max_depth': range(2,20,2),
             'min_samples_leaf': range(2,10,2),
             'min_impurity_decrease': np.linspace(0,0.5,10)}

gs = GridSearchCV(classifier, param_grid=param_grid)
gs.fit(x_tr, y_tr)

y_pred = gs.predict(x_te)
accuracy_score(y_te, y_pred)
\end{minted}

\caption{Código usado para implementar o Grid Search}
\end{listing}

\subsubsection{Padronização dos dados}

Para alguns dos modelos, a diferente amplitude dos atributos numéricos influenciava diretamente na acurácia do classificador. Como por exemplo no k-NN em que atributos que podiam chegar a valores maiores acabavam tendo maior peso no cálculo da distância. Por esse motivo, utilizamos a biblioteca de pré processamento do sklearn, mais especificamente o \textbf{StandardScaler}. Esta ferramenta permite redimensionar a distribuição dos valores de forma que a média dos valores observados é 0 e o desvio padrão é 1.

\section{Apresentação dos Resultados}

Os modelos testados foram: kNN, Naive Bayes, Random Forest e Decision Tree. Abaixo constam os resultados obtidos em uma das execuções do caderno Jupyter (vide repositório). Entretanto, é digno de menção que estes números estão sujeitos a variação.

%\begin{table}
%\caption{This is an example of Table legend.}
%\centering
%\includegraphics{bozku.t1.eps}
%\label{tab1}
%\end{table}

\vspace{0.5cm}

\begin{tabular}{ |p{3cm}|p{3cm}|p{3cm}|  }
\hline
 \textbf{Algoritmo} & \textbf{Acurácia} & \textbf{Piora}\footnotemark \\
 \hline
 Random Forest & 83.1\% & n/a \\
 Decision Tree & 81.5\% & 1.6\% \\
 kNN & 78.4\% & 4.7\% \\
 Naive Bayes & 23\% & 60.1\% \\
 \hline
\end{tabular}

\footnotetext[1]{Em relação ao melhor algoritmo.}

\section{Conclusão}

Após a conclusão de todas as etapas necessárias para a implementação do modelo, conclui-se ter logrado êxito quanto à previsão da performance dos alunos se baseando nas métricas supramencionadas, com precisão acima de 80\%.

Com isso, encerramos este relatório.


%% \ackrule

\bibliographystyle{IEEEtran}
\bibliography{thesis}

%\section*{Biographies}

%\textbf{P. W. Wachulak} received the degree${\ldots}$ \\[6pt]
%\textbf{M. C. Marconi} received the degree${\ldots}$ \\[6pt]
%\textbf{R. A. Bartels} received the degree${\ldots}$ \\[6pt]
%\textbf{C. S. Menoni} received the degree${\ldots}$ \\[6pt]
%\textbf{J. J. Rocca} received the degree${\ldots}$



\end{document}